version: '3.8'

services:
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_data:/qdrant/storage
    restart: always

  # Ollama service (optional - assuming user might run it locally or wants it containerized)
  # Keeping it simple for now as requested "Podman Compose (Qdrant, Ollama, vLLM)"
  # Note: Ollama often requires GPU passthrough which can be tricky in containers without proper setup.
  # For this POC, we will assume Ollama is accessible at host:11434 or via this container.
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: always

volumes:
  ollama_data:
